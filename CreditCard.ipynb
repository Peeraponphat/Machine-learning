{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUp5tcEWrFJM",
        "outputId": "cdaccdce-9a51-4988-ed50-2b7deb7c1fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scout with library"
      ],
      "metadata": {
        "id": "BRoud10WrSeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Installing Libraries ---\n",
        "!pip install pycaret"
      ],
      "metadata": {
        "id": "4IMEFXl3rF9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c9d03d-7e93-4fad-f2b5-4e16c82909bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycaret\n",
            "  Downloading pycaret-2.3.10-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imbalanced-learn==0.7.0\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.1/167.1 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba<0.55\n",
            "  Downloading numba-0.54.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.2.2)\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from pycaret) (7.9.0)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.5)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.2.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.11.2)\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from pycaret) (7.7.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy<2.4.0\n",
            "  Downloading spacy-2.3.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<=1.5.4\n",
            "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas-profiling>=2.8.0\n",
            "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.3.5)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.7)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.8.2.2)\n",
            "Collecting pyyaml<6.0.0\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pyod\n",
            "  Downloading pyod-1.0.7.tar.gz (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.7/147.7 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn==0.7.0->pycaret) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.23.2->pycaret) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim<4.0.0->pycaret) (6.3.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (3.0.5)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (5.3.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (3.6.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->pycaret) (0.38.4)\n",
            "Collecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.20.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (3.0.9)\n",
            "Collecting numpy>=1.13.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.38,>=0.37.0rc1\n",
            "  Downloading llvmlite-0.37.0-cp38-cp38-manylinux2014_x86_64.whl (26.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pycaret) (2022.7.1)\n",
            "Collecting ydata-profiling\n",
            "  Downloading ydata_profiling-4.0.0-py2.py3-none-any.whl (344 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.4.1->pycaret) (8.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (4.64.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (3.0.8)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (0.7.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (2.0.7)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (2.25.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (0.10.1)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (1.0.9)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "  Downloading yellowbrick-1.4-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.4/271.4 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.13.3\n",
            "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (0.4.3)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.9.3.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (2.11.3)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (0.4)\n",
            "Collecting packaging<23\n",
            "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (3.19.6)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (1.4.46)\n",
            "Requirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (3.4.1)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (2.2.1)\n",
            "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->pycaret) (2022.6.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Importing Libraries ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as mso\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import pycaret\n",
        "from pycaret.classification import *\n",
        "import plotly.express as px\n",
        "from pandas_profiling import ProfileReport\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "# --- Libraries Settings ---\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['figure.dpi'] = 100"
      ],
      "metadata": {
        "id": "ls4VMSBJrKFN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "81a975d8-d8de-4b07-cc8f-33b52614925e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0e29a3c20a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sc"
      ],
      "metadata": {
        "id": "xr0rz6n6rA5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Reading Dataset ---\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/colab/data/Application_Data.csv\")\n",
        "df.head().style.background_gradient(cmap='YlOrBr').set_properties(**{'font-family': 'Segoe UI'}).hide_index()"
      ],
      "metadata": {
        "id": "9u8DjAKCrMNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Print Dataset Info ---\n",
        "print('\\033[93m\\033[1m'+'.: Imported Dataset Info :.'+'\\033[0m')\n",
        "print('\\033[93m*' * 28+'\\033[0m')\n",
        "print('Total Rows:'+'\\033[93m\\033[1m', df.shape[0])\n",
        "print('\\033[0m'+'Total Columns:'+'\\033[93m\\033[1m', df.shape[1])\n",
        "print('\\033[0m\\033[93m'+'*' * 28+'\\033[0m')\n",
        "print('\\n')\n",
        "\n",
        "# --- Print Dataset Detail ---\n",
        "print('\\033[93m\\033[1m'+'.: Dataset Details :.'+'\\033[0m')\n",
        "print('\\033[0m\\033[93m'+'*' * 22+'\\033[0m')\n",
        "df.info(memory_usage = False)"
      ],
      "metadata": {
        "id": "lTL-Z4disYfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "///////////////////////"
      ],
      "metadata": {
        "id": "QNuiMUgXRmRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create Prediction & Modeling Data ---\n",
        "df_modeling = df.sample(frac=0.9, random_state=123)\n",
        "df_unseen = df.drop(df_modeling.index)\n",
        "df_modeling.reset_index(inplace=True, drop=True)\n",
        "df_unseen.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# --- Shape of Modeling & Prediction Data ---\n",
        "print('\\033[93m\\033[1m'+'.: Data for Modeling :.'+'\\033[0m')\n",
        "print('\\033[93m*' * 24+'\\033[0m')\n",
        "print('Total Observations / Total columns: ' + str(df_modeling.shape))\n",
        "print('\\n')\n",
        "print('\\033[93m\\033[1m'+'.: Data for Predictions (Unseen) :.'+'\\033[0m')\n",
        "print('\\033[93m*' * 36+'\\033[0m')\n",
        "print('Total Observations / Total Columns: ' + str(df_unseen.shape))"
      ],
      "metadata": {
        "id": "e9OhanOosfDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setting Up PyCaret ---\n",
        "stp = setup(data = df_modeling, target = 'Status', train_size = 0.8,\n",
        "            categorical_features = ['Applicant_Gender','Owned_Car','Owned_Realty', 'Income_Type','Education_Type',\n",
        "                                    'Family_Status', 'Housing_Type','Owned_Mobile_Phone','Owned_Work_Phone', \n",
        "                                    'Owned_Phone','Owned_Email','Job_Title'], \n",
        "            ignore_features = ['Applicant_ID'], fix_imbalance = True, silent = True, session_id=123)"
      ],
      "metadata": {
        "id": "dFKUAMMEtPzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Using `compare_models()` ---\n",
        "best_model = compare_models()"
      ],
      "metadata": {
        "id": "jCsF3_v_upXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Print `best_model` ---\n",
        "print(best_model)"
      ],
      "metadata": {
        "id": "TToM_Urkusog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start"
      ],
      "metadata": {
        "id": "pzB0pWAIuPiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Reading Dataset ---\n",
        "dd= pd.read_csv(\"/content/drive/MyDrive/colab/data/Application_Data.csv\")\n",
        "dd.head().style.background_gradient(cmap='YlOrBr').set_properties(**{'font-family': 'Segoe UI'}).hide_index()"
      ],
      "metadata": {
        "id": "e5wNl2GeULV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore data"
      ],
      "metadata": {
        "id": "gpDN5sCaquMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd.isnull()"
      ],
      "metadata": {
        "id": "9pR9NSJKU23g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.shape"
      ],
      "metadata": {
        "id": "ev4ac-MscMHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.info()"
      ],
      "metadata": {
        "id": "DyMcsvskdQs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.describe()"
      ],
      "metadata": {
        "id": "KuJ-_f4YdWYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.isnull().sum()"
      ],
      "metadata": {
        "id": "87yZTEZ9djD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.drop('Applicant_ID', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "og_MnHFYdqNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd['Status'].value_counts()"
      ],
      "metadata": {
        "id": "hCAslzGqW4BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head()"
      ],
      "metadata": {
        "id": "-NK8gMk0eFtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, there is no column (Feature) which is highly co-related with 'Status'\n",
        "plt.figure(figsize = (8,8))\n",
        "sns.heatmap(dd.corr(), annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R7-TAr8WfLm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of application are submitted by Female's\n",
        "plt.pie(dd['Applicant_Gender'].value_counts(), labels=['F', 'M'], autopct='%1.2f%%')\n",
        "plt.title('% of Applications submitted based on Gender')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A8zmc0bVfVbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of application are approved for Female's\n",
        "plt.pie(dd[dd['Status']==0]['Applicant_Gender'].value_counts(), labels=['F', 'M'], autopct='%1.2f%%')\n",
        "plt.title('% of Applications Approved based on Gender')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I6X8Km96fhiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's dont own a car\n",
        "plt.pie(dd['Owned_Car'].value_counts(), labels=['No', 'Yes'], autopct='%1.2f%%')\n",
        "plt.title('% of Applications submitted based on owning a Car')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lFlDT5eYf9Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's don't have any children\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.pie(dd['Total_Children'].value_counts(), labels=dd['Total_Children'].value_counts().index, autopct='%1.2f%%')\n",
        "plt.title('% of Applications submitted based on Children count')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tHatWwRkgJf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's income lies between 1 to 3 lakh\n",
        "plt.hist(dd['Total_Income'], bins=20)\n",
        "plt.xlabel('Total Annual Income')\n",
        "plt.title('Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "umOiuFNqhB5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's are working professional\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.pie(dd['Income_Type'].value_counts(), labels=dd['Income_Type'].value_counts().index, autopct='%1.2f%%')\n",
        "plt.title('% of Applications submitted based on Income Type')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h96eKB6BjJpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's completed the Secondary Education\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(dd['Education_Type'].value_counts(), labels=dd['Education_Type'].value_counts().index, autopct='%1.2f%%')\n",
        "plt.title('% of Applications submitted based on Education')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xjZzbmE8jrXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's are married\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.barplot(dd['Family_Status'].value_counts().index, dd['Family_Status'].value_counts().values)\n",
        "plt.title('% of Applications submitted based on Family Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WD9meWLlj47L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's lives in House / Apartment\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.barplot(dd['Housing_Type'].value_counts().index,dd['Housing_Type'].value_counts().values)\n",
        "plt.title('% of Applications submitted based on Housing Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pDKKrerskJld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's are 25 to 65 years old\n",
        "plt.hist(dd['Applicant_Age'], bins=20)\n",
        "plt.xlabel('Age')\n",
        "plt.title('Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VsEnlOTtkVsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applicatant's are Employed for 0 to 7 years\n",
        "plt.hist(dd['Years_of_Working'], bins=20)\n",
        "plt.xlabel('No of Years Employed')\n",
        "plt.title('Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jr_zJG7gklSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows that, majority of applications are rejected if Total income & years of Employment is less\n",
        "sns.scatterplot(dd['Years_of_Working'], dd['Total_Income'], hue=dd['Status'])\n",
        "plt.title('Scatter Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GsqLhNERk0mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare data"
      ],
      "metadata": {
        "id": "sbpqxOq0qjeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = dd.columns[(dd.dtypes =='object').values].tolist()\n",
        "cat_columns"
      ],
      "metadata": {
        "id": "-BiPTF8jlMfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting all Non-Numerical Columns to Numerical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in cat_columns:\n",
        "        globals()['LE_{}'.format(col)] = LabelEncoder()\n",
        "        dd[col] = globals()['LE_{}'.format(col)].fit_transform(dd[col])\n",
        "dd.head()    "
      ],
      "metadata": {
        "id": "r5gjDiHjlTlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_columns:\n",
        "    print(col , \"  : \", globals()['LE_{}'.format(col)].classes_)"
      ],
      "metadata": {
        "id": "X0JSdg3Fldc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.corr()"
      ],
      "metadata": {
        "id": "r9joGsTjlig5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = dd.drop(['Status'], axis=1)\n",
        "label = dd['Status']"
      ],
      "metadata": {
        "id": "f_K07ZbAlpbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "id": "A2GMzSZdlza_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label.head()"
      ],
      "metadata": {
        "id": "Q7zT6roUl3nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model"
      ],
      "metadata": {
        "id": "wq378hQtqb0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features,\n",
        "                                                    label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state = 10)"
      ],
      "metadata": {
        "id": "Ua8sgcmXl5i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(x_train, y_train)\n",
        "\n",
        "print('Logistic Model Accuracy : ', log_model.score(x_test, y_test)*100, '%')\n",
        "\n",
        "prediction = log_model.predict(x_test)\n",
        "print('\\nConfusion matrix :')\n",
        "print(confusion_matrix(y_test, prediction))\n",
        "      \n",
        "print('\\nClassification report:')      \n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "-4nDYJmLmBJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine classification\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC()\n",
        "\n",
        "svc_model.fit(x_train, y_train)\n",
        "\n",
        "print('Support Vector Classifier Accuracy : ', svc_model.score(x_test, y_test)*100, '%')\n",
        "\n",
        "prediction = svc_model.predict(x_test)\n",
        "print('\\nConfusion matrix :')\n",
        "print(confusion_matrix(y_test, prediction))\n",
        "      \n",
        "print('\\nClassification report:')      \n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "8lcdq0lLmMub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 7)\n",
        "\n",
        "knn_model.fit(x_train, y_train)\n",
        "\n",
        "print('KNN Model Accuracy : ', knn_model.score(x_test, y_test)*100, '%')\n",
        "\n",
        "prediction = knn_model.predict(x_test)\n",
        "print('\\nConfusion matrix :')\n",
        "print(confusion_matrix(y_test, prediction))\n",
        "      \n",
        "print('\\nClassification report:')      \n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "toZ12JPdmqdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balancing dataset ทำให้ข้อมูลไม่กระจายเฉลี่ยข้อมูลทำให้นำไปเทรนให้ผลดีขึ้น"
      ],
      "metadata": {
        "id": "D4d8ghoBpSQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling all features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "MMS = MinMaxScaler()\n",
        "x_train_scaled = pd.DataFrame(MMS.fit_transform(x_train), columns=x_train.columns)\n",
        "x_test_scaled = pd.DataFrame(MMS.transform(x_test), columns=x_test.columns)"
      ],
      "metadata": {
        "id": "9U-7Lm53nSZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding samples to minority class using SMOTE Synthetic Minority Over-sampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "\n",
        "x_train_oversam, y_train_oversam = oversample.fit_resample(x_train_scaled, y_train)\n",
        "x_test_oversam, y_test_oversam = oversample.fit_resample(x_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "fBDQtnXKnfZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original majority and minority class\n",
        "y_train.value_counts(normalize=True)*100"
      ],
      "metadata": {
        "id": "CVp9cLpznh_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after using SMOTE \n",
        "y_train_oversam.value_counts(normalize=True)*100"
      ],
      "metadata": {
        "id": "_1T1mvVOnloh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model after Balancing"
      ],
      "metadata": {
        "id": "nA6-7JqOpNQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(x_train_oversam, y_train_oversam)\n",
        "\n",
        "print('Logistic Model Accuracy : ', log_model.score(x_test_oversam, y_test_oversam)*100, '%')\n",
        "\n",
        "prediction = log_model.predict(x_test_oversam)\n",
        "print('\\nConfusion matrix :')\n",
        "print(confusion_matrix(y_test_oversam, prediction))\n",
        "      \n",
        "print('\\nClassification report:')      \n",
        "print(classification_report(y_test_oversam, prediction))"
      ],
      "metadata": {
        "id": "ujy0wltunoz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine classification\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC()\n",
        "\n",
        "svc_model.fit(x_train_oversam, y_train_oversam)\n",
        "\n",
        "print('Support Vector Classifier Accuracy : ', svc_model.score(x_test_oversam, y_test_oversam)*100, '%')\n",
        "\n",
        "prediction = svc_model.predict(x_test_oversam)\n",
        "print('\\nConfusion matrix :')\n",
        "print(confusion_matrix(y_test_oversam, prediction))\n",
        "      \n",
        "print('\\nClassification report:')      \n",
        "print(classification_report(y_test_oversam, prediction))"
      ],
      "metadata": {
        "id": "n3hSAUztnsuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K Nearest Neighbor classification\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 7)\n",
        "\n",
        "knn_model.fit(x_train_oversam, y_train_oversam)\n",
        "\n",
        "print('KNN Model Accuracy : ', knn_model.score(x_test_oversam, y_test_oversam)*100, '%')\n",
        "\n",
        "prediction = knn_model.predict(x_test_oversam)\n",
        "print('\\nConfusion matrix :')\n",
        "print(confusion_matrix(y_test_oversam, prediction))\n",
        "      \n",
        "print('\\nClassification report:')      \n",
        "print(classification_report(y_test_oversam, prediction))"
      ],
      "metadata": {
        "id": "whIdjffkn3eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation ยืนยันค่าความถูกต้องของmodel"
      ],
      "metadata": {
        "id": "g50LeMeZpB2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " K-Fold Cross Validation"
      ],
      "metadata": {
        "id": "8jTiBb8UpJlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = KFold(5)"
      ],
      "metadata": {
        "id": "37fqPnO9oMd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "results=cross_val_score(log_model,features,label,cv=kfold)\n",
        "print(results*100,'\\n')\n",
        "\n",
        "print(np.mean(results)*100)"
      ],
      "metadata": {
        "id": "j0Ul31RQoSlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine classification\n",
        "\n",
        "results=cross_val_score(svc_model,features,label,cv=kfold)\n",
        "print(results*100,'\\n')\n",
        "\n",
        "print(np.mean(results)*100)"
      ],
      "metadata": {
        "id": "vYtfsJiSoYSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K Nearest Neighbor classification\n",
        "\n",
        "results=cross_val_score(knn_model,features,label,cv=kfold)\n",
        "print(results*100,'\\n')\n",
        "\n",
        "print(np.mean(results)*100)"
      ],
      "metadata": {
        "id": "AAO5t3jooarc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stratified Shuffle Split"
      ],
      "metadata": {
        "id": "kHvHSbJvo_TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "ssplit=StratifiedShuffleSplit(n_splits=5,test_size=0.30)"
      ],
      "metadata": {
        "id": "JLIrK8-Bopm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "results=cross_val_score(log_model,features,label,cv=ssplit)\n",
        "print(results*100,'\\n')\n",
        "\n",
        "print(np.mean(results)*100)"
      ],
      "metadata": {
        "id": "EtQQn0M-otqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine classification\n",
        "\n",
        "results=cross_val_score(svc_model,features,label,cv=ssplit)\n",
        "print(results*100,'\\n')\n",
        "\n",
        "print(np.mean(results)*100)"
      ],
      "metadata": {
        "id": "xPwn8xI4owHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K Nearest Neighbor classification\n",
        "\n",
        "results=cross_val_score(knn_model,features,label,cv=ssplit)\n",
        "print(results*100,'\\n')\n",
        "\n",
        "print(np.mean(results)*100)"
      ],
      "metadata": {
        "id": "6DCdqBquox1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "สรุป:ในการใช้model ทั้งหมด 3 โมเดลมี Logistic Regression,Support Vector Machine classification,K Nearest Neighbor classification กับ dataset นี้ ผลคือโดยรวม Logistic Regression ให้ค่า accuracy มากที่สุด"
      ],
      "metadata": {
        "id": "bwzTCOsYwM-N"
      }
    }
  ]
}